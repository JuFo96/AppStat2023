{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Propagation using Random Gaussian Numbers\n",
    "\n",
    "Example calculation of propagating uncertainties, both when adding and multiplying number, and also in the general case. The propagation can be done both analytically (using the error propagation formula) and also using simulation.\n",
    "\n",
    "The example is based on FIRST doing the error propagation **analytically**, and then verifying it by running a so-called Monte-Carlo (MC) program, which uses random numbers for propagating errors.\n",
    "\n",
    "## References:\n",
    "- Barlow: page 48-61\n",
    "- Bevington: page 36-48\n",
    "\n",
    "## Author(s), contact(s), and dates:\n",
    "- Author: Troels C. Petersen (NBI)\n",
    "- Email:  petersen@nbi.dk\n",
    "- Date:   8th of November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "DO THE FOLLOWING ANALYTICAL EXERCISE FIRST!!!\n",
    "\n",
    "1. A class of students estimate by eye, that the length of the table in Auditorium A is $L = (3.5\\pm 0.4)$m, and that the width is $W = (0.8\\pm 0.2)$m.\n",
    "\n",
    "   Assuming that there is no correlation between these two measurements, calculate ANALYTICALLY what the Perimeter (P), area (A), and diagonal (D) length is including (propagated) uncertainties. Repeat the calculation, given that the correlation between length and width is $\\rho(L,W) = 0.5$ - not an unreasonable number, given that they are estimated by the same (uncertain) scale.\n",
    "   \n",
    "NOTE: This is a complete standard problem, that you will be asked to solve again and again in the course. For this reason, make sure that you understand how to do it, and become good at doing it reasonably fast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perimeter\n",
    "$P = 2L + 2W$\n",
    "\n",
    "$\\frac{dP}{dL} = 2$\n",
    "$\\frac{dP}{dW} = 2$\n",
    "\n",
    "$\\sigma_P^2 = (\\frac{dP}{dL})^2\\sigma_L^2 + (\\frac{dP}{dW})^2\\sigma_W^2 = 0.64 + 0.16 = 0.8$\n",
    "\n",
    "$P = 8.6 \\pm 0.9$\n",
    "\n",
    "### Correlation term\n",
    "$\\rho(L,W) = \\frac{V_{LW}}{\\sigma_L\\sigma_W}$\n",
    "\n",
    "$\\sigma_P^2 = (\\frac{dP}{dL})^2\\sigma_L^2 + (\\frac{dP}{dW})^2\\sigma_W^2 + 2\\frac{dP}{dL}\\frac{dP}{dW}\\rho(L,W)\\sigma_L\\sigma_W = 0.64 + 0.16 + 2*2*2*0.5*0.4*0.2 = 1.1$\n",
    "\n",
    "$P = 8.6 \\pm 1.1$\n",
    "\n",
    "## Area\n",
    "$ A = L\\cdot W $\n",
    "\n",
    "$ \\frac{dA}{dL} = W$\n",
    "$ \\frac{dA}{dW} = L$\n",
    "\n",
    "$\\sigma_A^2 = W^2\\sigma_L^2 + L^2\\sigma_W^2 = 0.1 + 0.5 = 0.6$\n",
    "\n",
    "$ A = 2.8 \\pm 0.8 $\n",
    "\n",
    "### Correlation term\n",
    "$\\rho(L,W) = \\frac{V_{LW}}{\\sigma_L\\sigma_W}$\n",
    "\n",
    "$\\sigma_{A_{corr}}^2 = 2\\frac{dA}{dL}\\frac{dA}{dW}\\rho(L,W)\\sigma_L\\sigma_W = 2*W*L*0.5*0.4*0.2 = 0.2$\n",
    "\n",
    "$A = 8.6 \\pm 0.9$\n",
    "\n",
    "## Diagonal\n",
    "\n",
    "$ D = \\sqrt{L^2 + W^2} $\n",
    "\n",
    "$ \\frac{dD}{dW} = \\frac{W}{\\sqrt{(L^2 + W^2)}}$ \\, \n",
    "$ \\frac{dD}{dL} = \\frac{L}{\\sqrt{(L^2 + W^2)}}$\n",
    "\n",
    "$\\sigma_D^2 = \\frac{W^2\\sigma_W^2}{(L^2 + W^2)} + \\frac{L^2\\sigma_L^2}{(L^2 + W^2)} = 0.002 + 0.15 = 0.15$\n",
    "\n",
    "$ D = 3.6 \\pm 0.4 $\n",
    "\n",
    "### Correlation term\n",
    "$\\rho(L,W) = \\frac{V_{LW}}{\\sigma_L\\sigma_W}$\n",
    "\n",
    "$\\sigma_{D_{corr}}^2 = 2\\frac{dD}{dL}\\frac{dD}{dW}\\rho(L,W)\\sigma_L\\sigma_W = 2*\\frac{W}{\\sqrt{(L^2 + W^2)}}*\\frac{L}{\\sqrt{(L^2 + W^2)}}*0.5*0.4*0.2 = 0.02$\n",
    "\n",
    "$A = 3.6 \\pm 0.4$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1   =  3.5\n",
    "sig1  =  0.4\n",
    "mu2   =  0.8\n",
    "sig2  =  0.2\n",
    "rho12 =  0.5          # Correlation parameter!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note on analytic solutions with SymPy:\n",
    "\n",
    "Python includes symbolic algebra in the package *SymPy*, which is both simple and powerful (and in Python). In addition, printing with Latex can also be included (see below), which (in combination) is very nice.\n",
    "\n",
    "Below is a SymPy and Latex example with the hope that it will wet your appetite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import Latex\n",
    "\n",
    "def lprint(*args,**kwargs):\n",
    "    \"\"\"Pretty print arguments as LaTeX using IPython display system \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    args : tuple \n",
    "        What to print (in LaTeX math mode)\n",
    "    kwargs : dict \n",
    "        optional keywords to pass to `display` \n",
    "    \"\"\"\n",
    "    display(Latex('$$'+' '.join(args)+'$$'),**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:11: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "<>:11: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "C:\\Users\\Juliu\\AppData\\Local\\Temp\\ipykernel_16036\\138645052.py:11: SyntaxWarning: 'int' object is not callable; perhaps you missed a comma?\n",
      "  A = b**2(1-e**2)**(0.5)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16036\\138645052.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Perimeter:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Define relation, and print:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0mlprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbols\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'A'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "# Import SymPy: \n",
    "from sympy import * \n",
    "import numpy as np\n",
    "    \n",
    "# Define variables:\n",
    "A,b,e = symbols(\"A, b, e\")\n",
    "dB,dE,dA = symbols(\"sigma_B, sigma_E, sigma_A\")\n",
    "\n",
    "# Perimeter:\n",
    "# Define relation, and print:\n",
    "A = b**2(1-e**2)**(0.5)\n",
    "lprint(latex(Eq(symbols('A'),A)))\n",
    "\n",
    "# Calculate uncertainty and print:\n",
    "dP = sqrt((A.diff(B) * dB)**2 + (A.diff(e) * de)**2 + 2*P.diff(L)*P.diff(W)*dL*dW*0.5) \n",
    "lprint(latex(Eq(symbols('sigma_P'), dP)))\n",
    "\n",
    "# Turn expression into numerical functions \n",
    "fP = lambdify((L,W),P)\n",
    "fdP = lambdify((L,dL,W,dW),dP)\n",
    "\n",
    "# Define values and their errors\n",
    "vL, vdL = mu1,sig1\n",
    "vW, vdW = mu2,sig2\n",
    "rho = rho12\n",
    "\n",
    "# Numerically evaluate expressions and print \n",
    "vP = fP(vL,vW)\n",
    "vdP = fdP(vL,vdL,vW,vdW)\n",
    "lprint(fr'P = ({vP:.1f} \\pm {vdP:.1f})\\,\\mathrm{{m}}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# NOTE: Do the above analytical calculation before you continue below! Possibly use SymPy for the differentiations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np                                     # Matlab like syntax for linear algebra and functions\n",
    "import matplotlib.pyplot as plt                        # Plots and figures like you know them from Matlab\n",
    "import seaborn as sns                                  # Make the plots nicer to look at\n",
    "from iminuit import Minuit                             # The actual fitting tool, better than scipy's\n",
    "import sys                                             # Modules to see files and folders in directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../External_Functions')\n",
    "from ExternalFunctions import Chi2Regression\n",
    "from ExternalFunctions import nice_string_output, add_text_to_ax # useful functions to print fit results on figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error propagation - Simulation\n",
    "\n",
    "Now we want to try to see, if we can solve the above error propagation problem using simulation. The method is relatively straight forward: You simply take \"realistic\" values of the input parameters x (here Length (x1) and Width (x2)), calculate the resulting value y (here Perimeter, Area, and Diagonal), and do this many times. The resulting distribution of y should be centered around the value y(x1,x2), and the standard deviation should reflect the uncertainty in y from the uncertainties in the input variables.\n",
    "\n",
    "This is a much more clumsy way of calculating the uncertainty, but comes with the advantage, that if the resulting uncertainty is not Gaussian, then one can actually see this (i.e. it avoids the assumptions used in the usual error propagation formula)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we set the parameters of the program:\n",
    "N_exp = 10000           # Number of \"experiments\" (i.e. drawing from random distributions)\n",
    "save_plots = False\n",
    "r = np.random\n",
    "r.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, check if the correlation is valid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (-1.0 <= rho12 <= 1.0): \n",
    "    raise ValueError(f\"Correlation factor not in interval [-1,1], as it is {rho12:6.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producing random numbers with a correlation:\n",
    "\n",
    "Below we have used the build in Numpy method for producing two random Gaussian numbers with a correation between them.\n",
    "\n",
    "You can also do this \"yourself\", see Barlow page 42-44 for method. Essentially, the method is to generate uncorrelated Gaussian numbers, and then \"rotating\" these, where the amount of rotation controls the correlation wanted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce random numbers with (a possible) correlation:\n",
    "cov = np.array([[sig1**2, rho12*sig1*sig2],\n",
    "                [rho12*sig1*sig2, sig2**2]])\n",
    "x12_all = np.random.multivariate_normal([mu1, mu2], cov, size=N_exp)\n",
    "x1 = x12_all[:, 0] # Parameter 1 Length L\n",
    "x2 = x12_all[:, 0] # Parameter 2 Width W\n",
    "\n",
    "# Now we use the input variables (x1 and x2) to calculate y:\n",
    "y_all = 2*x12_all[:,0] + 2*x12_all[:,1]         # Silly formula - you have to put this in yourself!\n",
    "P_sim = 2*x12_all[:,0] + 2*x12_all[:,1]\n",
    "A_sim = x12_all[:, 0] * x12_all[:, 1]\n",
    "D_sim = np.sqrt(x12_all[:, 0]**2 + x12_all[:, 1])\n",
    "y1 = np.log(np.square(x1*np.tan(x2))+np.sqrt((x1-x2)/(np.cos(x2)+1.0+x1)))\n",
    "y2 = 1.1+np.sin(20*x1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Plot both input distribution and resulting 2D-histogram on screen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x12_all[:, 0])\n",
    "plt.hist(x12_all[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 8))\n",
    "counts, xedges, yedges, im = ax.hist2d(x12_all[:,0], x12_all[:,1], bins=[120, 80], range=[[0.0, 6.0], [-1.0, 3.0]], cmin=1)\n",
    "ax.plot([0.0, 6.0], [0.0, 0.0], \"--k\")    # NOTE: Dashed black line from [x1, x2], [y1, y2] with dashed line\n",
    "fig.colorbar(im)\n",
    "\n",
    "ax.set(title='Histogram of lengths (x) and widths (y)',\n",
    "       xlabel='x', \n",
    "       ylabel='y'\n",
    "      )\n",
    "\n",
    "d = {'Entries': len(x12_all),\n",
    "     'Mean x': x12_all[:,0].mean(),\n",
    "     'Mean y': x12_all[:,1].mean(),\n",
    "     'Std x': x12_all[:,0].std(ddof=1),\n",
    "     'Std y': x12_all[:,1].std(ddof=1),\n",
    "    }\n",
    "\n",
    "text = nice_string_output(d, extra_spacing=2, decimals=3)\n",
    "add_text_to_ax(0.02, 0.97, text, ax, fontsize=15);\n",
    "\n",
    "fig.tight_layout()\n",
    "fig\n",
    "\n",
    "if save_plots :\n",
    "    fig.savefig(\"Dist_2Dgauss.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the resulting distribution:\n",
    "\n",
    "Now we look at the `y_all` distribution, which should be Gaussian if the error propagation formula holds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always make sure, that you control the binning and range!\n",
    "nbins = 100\n",
    "xmin, xmax = -100, 100\n",
    "binwidth = (xmax-xmin)/nbins\n",
    "\n",
    "fig2, ax2 = plt.subplots(figsize=(16, 6));\n",
    "counts, bin_edges, _ = ax2.hist(y2, nbins, range=(xmin, xmax), histtype='step', linewidth=2)\n",
    "bin_centers = (bin_edges[1:] + bin_edges[:-1])/2\n",
    "s_counts = np.sqrt(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the distribution of \"whatever you put into it\" (initially x1-2*x2), which shows what output you get and what uncertainty to expect (given by the width - think about this!). We can thus get the result by simply recording the mean and width (SD):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = y2.mean()\n",
    "std = y2.std(ddof=1)\n",
    "print(f\"  Mean = {mean:5.3f},    Std = {std:5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are in principle not even sure, if this distribution is Gaussian, so in order to check this, we draw a Gaussian on top using the above mean and standard deviation values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, N, mu, sigma):\n",
    "    return N * binwidth / (sigma*np.sqrt(2*np.pi)) * np.exp(-0.5* (x-mu)**2/sigma**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.linspace(xmin, xmax, 1000)\n",
    "yaxis = gaussian(xaxis, N_exp, mean, std)\n",
    "ax2.plot(xaxis, yaxis, linewidth=2)\n",
    "fig2.tight_layout()\n",
    "fig2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = gaussian(xaxis, N_exp, 50, 20)\n",
    "plt.plot(xaxis, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if save_plots:\n",
    "    fig2.savefig(\"Dist_ErrorProp.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Questions:\n",
    "\n",
    "0. First solve the problem of obtaining the Perimeter, Area & Diagonal with uncertainty ANALYTICALLY.\n",
    "\n",
    "1. Now look at the program, and assure yourself that you understand what is going on. Put in the correct expression for y in terms of x1=L and x2=W in order to calculate the perimeter, area, and diagonal length, and run the program. Does the output correspond well with the results you expected from your analytical calculations to begin with?\n",
    "\n",
    "2. Imagine that you wanted to know the central value and uncertainty of y1 and y2, given the\n",
    "   same above PDFs for `x1`=$L$ and `x2`=$W$:\n",
    "   \n",
    "     `y1 = log(square(x1*tan(x2))+sqrt((x1-x2)/(cos(x2)+1.0+x1)))`\n",
    "     \n",
    "     `y2 = 1.1+sin(20*x1)`\n",
    "\n",
    "   Get the central value of y, and see if you can quickly differentiate this with\n",
    "   respect to `x1` and `x2`, and thus predict what uncertainty to expect for y using\n",
    "   the error propagation formula. It is (for once) OK to give up on the first expression :-)\n",
    "   Next, try to estimate the central value and uncertainty using random numbers\n",
    "   like above - do you trust this result more? And are the distributions Gaussian?\n",
    "\n",
    "\n",
    "### Advanced questions:\n",
    "\n",
    "3. Try to generate `x1` and `x2` with non-linear correlation, which yields zero linear correlation,\n",
    "   and see that despite not having any linear correlation, the result on perimeter, area, and diagonal\n",
    "   length is still affected.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning points:\n",
    "\n",
    "Through this exercise, you should understand, that uncertainties (errors in slang) propagation can be in **two ways**:\n",
    "1. **Analytically**, propergating the uncertainties by differentiating the formula/relation in question.\n",
    "2. **Numerically** (i.e. simulation), by using random numbers reflecting the uncertainties on the input parameters, and calculating the final resulting number many times from these, noting the variation.\n",
    "\n",
    "You should be capable of **using both methods** effortlessly and with confidence.\n",
    "\n",
    "The analytical method is simple and transparent, but not always robust, as it requires that the error propagation formula holds. The numerical method is simple and robust, but not transparent. Using both methods is a great way of cross checking.\n",
    "\n",
    "Finally, you should understand, that error propagation plays an essential role in science, and that it is also used in planning of experiments (to minimise the error on the final quantity of interest)."
   ]
  }
 ],
 "metadata": {
  "executable": "/usr/bin/env python",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
